{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96309356",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#Colab use\n",
    "#from google.colab import files\n",
    "#uploaded = files.upload()\n",
    "#import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b6ad3b1",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#standardization\n",
    "def standard_scaler(X_train, X_test):\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    X_train = scaler.fit_transform(X_train) #standardize based on train data\n",
    "    X_test = scaler.transform(X_test) #standardize test data\n",
    "    \n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a42fc868",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_true, y_pred, label='test'):\n",
    "    mse = mean_squared_error(y_true, y_pred) #calculate MSE\n",
    "    rmse = np.sqrt(mse) #calculate RMSE\n",
    "    variance = r2_score(y_true, y_pred) #calculate R2\n",
    "    print('{} set RMSE:{}, R2:{}'.format(label, rmse, variance))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7483044",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b30c949",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_names = ['ID', 'Cycle']\n",
    "setting_names = ['OpSet1', 'OpSet2', 'OpSet3']\n",
    "sensor_names = ['SensorMeasure{}'.format(i) for i in range(1,22)] \n",
    "col_names = index_names + setting_names + sensor_names\n",
    "\n",
    "train_data = pd.read_csv(\"../Data/train_set.csv\")\n",
    "test_data = pd.read_csv(\"../Data/test_set.csv\")\n",
    "true_RUL = pd.read_csv(\"../Data/RUL_FD001.txt\", sep='\\s+', header = None)\n",
    "\n",
    "#Colab use\n",
    "#train_data = pd.read_csv(io.BytesIO(uploaded['train_set.csv']))\n",
    "#test_data = pd.read_csv(io.BytesIO(uploaded['test_set.csv']))\n",
    "#true_RUL = pd.read_csv(io.BytesIO(uploaded['RUL_FD001.txt']), sep='\\s+', header = None)\n",
    "\n",
    "train_RUL = train_data['RUL']\n",
    "train_RUL = train_RUL.clip(upper = 125) #clip maximum cycle at 125\n",
    "test_RUL = test_data['RUL']\n",
    "\n",
    "train_data = train_data.drop(['RUL'], 1)\n",
    "test_data = test_data.drop(['RUL'], 1)\n",
    "\n",
    "test_data = test_data.groupby(['ID'])\n",
    "test_data = test_data.tail(1)\n",
    "\n",
    "#assign to new variable for easy understanding\n",
    "train = train_data\n",
    "train_y = train_RUL\n",
    "test = test_data.groupby(['ID']).tail(1) #get the last record for each engine\n",
    "test_y = true_RUL\n",
    "\n",
    "#only sensor value considered\n",
    "train = train[sensor_names]\n",
    "test = test[sensor_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9100dc",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7ceea0c",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#Principle Component Analysis\n",
    "def pca(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    #for reproducible result\n",
    "    np.random.seed(2)\n",
    "    \n",
    "    X_train, X_test = standard_scaler(X_train, X_test) #standardize data\n",
    "    \n",
    "    #rename columns after standardization\n",
    "    sensor_names = ['SensorMeasure{}'.format(i) for i in range(1,22)] \n",
    "    X_train = pd.DataFrame(X_train, columns = sensor_names).reset_index(drop = True)\n",
    "    X_test = pd.DataFrame(X_test, columns = sensor_names).reset_index(drop = True)\n",
    "\n",
    "    #-------------------------------Fitting Model----------------------------\n",
    "    # Make an instance of the Model\n",
    "    pca = PCA(0.95, random_state = 1) #95% of the variance (information) is retained\n",
    "\n",
    "    x1 = pca.fit_transform(X_train) #PCA based on train data\n",
    "    x2 = pca.transform(X_test) #transform test data\n",
    "    \n",
    "    #Graph to indicate information contains in each component\n",
    "    # fir = plt.figure(figsize=(8,5))\n",
    "    # sing_vals = np.arange(len(pca.components_)) + 1\n",
    "    # plt.plot(sing_vals, pca.explained_variance_ratio_, 'ro-', linewidth=2)\n",
    "    # plt.title('Scree Plot', fontsize = 20)\n",
    "    # plt.xlabel('Principal Component', fontsize = 20)\n",
    "    # plt.ylabel('Eigenvalue', fontsize = 20)\n",
    "    # plt.xticks(fontsize=10)\n",
    "    # plt.yticks(fontsize=10)\n",
    "    #------------------------------------------------------------------------\n",
    "    \n",
    "    #convert to data frame\n",
    "    X_train = pd.DataFrame(data = x1)\n",
    "    X_test = pd.DataFrame(data = x2)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890383bc",
   "metadata": {},
   "source": [
    "# Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7eff761d",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def support_vector_regression(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    #for reproducible result\n",
    "    np.random.seed(2)\n",
    "    \n",
    "    #------------------------------Train Model-------------------------------\n",
    "    SVRM = SVR()\n",
    "    \n",
    "    c = [int(x) for x in np.linspace(1, 15, num = 15)] #different value for C\n",
    "    epsilon = [int(x) for x in np.linspace(1, 20, num = 20)] #different value for epsilon\n",
    "\n",
    "    #Create the dictionary\n",
    "    param_grid = {'C': c,\n",
    "                  'epsilon': epsilon}\n",
    "    \n",
    "    #K-fold cross validation\n",
    "    cv = KFold(n_splits=10, shuffle = True, random_state = 1)\n",
    "    \n",
    "    #randomized search \n",
    "    rand_search = RandomizedSearchCV(SVRM, param_distributions = param_grid, \n",
    "                                     cv = cv, n_jobs=-1, random_state=1)\n",
    "    \n",
    "    rand_search.fit(X_train, y_train.values.ravel()) #train model\n",
    "    \n",
    "    #SVRM.fit(X_train, y_train.values.ravel()) #train model on default settings\n",
    "    #------------------------------------------------------------------------\n",
    "\n",
    "    #------------------------------Predict X---------------------------------\n",
    "    y_pred_train = rand_search.predict(X_train) #predict on train data\n",
    "    y_pred_test = rand_search.predict(X_test) #predict on test data\n",
    "    \n",
    "    #for default model\n",
    "    #y_pred_train = SVRM.predict(X_train)\n",
    "    #y_pred_test = SVRM.predict(X_test)\n",
    "    #------------------------------------------------------------------------\n",
    "    \n",
    "    #---------------------------------Accuracy-------------------------------\n",
    "    # Use score method to get accuracy of model\n",
    "    accuracy_score = rand_search.score(X_test, y_test)\n",
    "    #accuracy_score = SVRM.score(X_test, y_test) #for default model\n",
    "    print('Accuracy of Support Vector Regression on test set: {:.2f}'.format(accuracy_score))\n",
    "    #------------------------------------------------------------------------\n",
    "    \n",
    "    #---------------------------------RMSE & R2------------------------------\n",
    "    evaluate(y_train, y_pred_train, 'Train')\n",
    "    evaluate(y_test, y_pred_test, 'Test')\n",
    "    #------------------------------------------------------------------------\n",
    "    \n",
    "    #---------------------------------Best Param-----------------------------\n",
    "    print(rand_search.best_params_) #parameters that provide best result\n",
    "    #------------------------------------------------------------------------\n",
    "    \n",
    "    filename = '../Dashboard UI/Dashboard UI/model/SVR_model.sav'\n",
    "    pickle.dump(rand_search, open(filename, 'wb')) #save support vector regression model\n",
    "    \n",
    "    #Colab use\n",
    "    #filename = 'SVR_model.sav'\n",
    "    #pickle.dump(rand_search, open(filename, 'wb')) #save support vector regression model\n",
    "    #files.download('SVR_model.sav')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870497d2",
   "metadata": {},
   "source": [
    "# Working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "185b90b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Support Vector Regression on test set: 0.80\n",
      "Train set RMSE:18.134825968148295, R2:0.810624524045426\n",
      "Test set RMSE:18.37509717228015, R2:0.8044761480017149\n",
      "{'epsilon': 10, 'C': 10}\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = pca(train, test, train_y, test_y)\n",
    "\n",
    "support_vector_regression(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3399565",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
