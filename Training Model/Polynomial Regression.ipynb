{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8e6322e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "#Colab use\n",
    "#from google.colab import files\n",
    "#uploaded = files.upload()\n",
    "#import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4d5ab7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardization\n",
    "def standard_scaler(X_train, X_test):\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    X_train = scaler.fit_transform(X_train) #standardize based on train data\n",
    "    X_test = scaler.transform(X_test) #standardize test data\n",
    "    \n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85414eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_true, y_pred, label='test'):\n",
    "    mse = mean_squared_error(y_true, y_pred) #calculate MSE\n",
    "    rmse = np.sqrt(mse) #calculate RMSE\n",
    "    variance = r2_score(y_true, y_pred) #calculate R2\n",
    "    print('{} set RMSE:{}, R2:{}'.format(label, rmse, variance))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e63f4b9",
   "metadata": {},
   "source": [
    "# Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3e1f9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_names = ['ID', 'Cycle']\n",
    "setting_names = ['OpSet1', 'OpSet2', 'OpSet3']\n",
    "sensor_names = ['SensorMeasure{}'.format(i) for i in range(1,22)] \n",
    "col_names = index_names + setting_names + sensor_names\n",
    "\n",
    "train_data = pd.read_csv(\"../Data/train_set.csv\")\n",
    "test_data = pd.read_csv(\"../Data/test_set.csv\")\n",
    "true_RUL = pd.read_csv(\"../Data/RUL_FD001.txt\", sep='\\s+', header = None)\n",
    "\n",
    "#Colab use\n",
    "#train_data = pd.read_csv(io.BytesIO(uploaded['train_set.csv']))\n",
    "#test_data = pd.read_csv(io.BytesIO(uploaded['test_set.csv']))\n",
    "#true_RUL = pd.read_csv(io.BytesIO(uploaded['RUL_FD001.txt']), sep='\\s+', header = None)\n",
    "\n",
    "train_RUL = train_data['RUL']\n",
    "train_RUL = train_RUL.clip(upper = 125) #clip maximum cycle at 125\n",
    "test_RUL = test_data['RUL']\n",
    "\n",
    "train_data = train_data.drop(['RUL'], 1)\n",
    "test_data = test_data.drop(['RUL'], 1)\n",
    "\n",
    "test_data = test_data.groupby(['ID'])\n",
    "test_data = test_data.tail(1)\n",
    "\n",
    "#assign to new variable for easy understanding\n",
    "train = train_data\n",
    "train_y = train_RUL\n",
    "test = test_data.groupby(['ID']).tail(1) #get the last record for each engine\n",
    "test_y = true_RUL\n",
    "\n",
    "#only sensor value considered\n",
    "train = train[sensor_names]\n",
    "test = test[sensor_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e95569d",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "555ead13",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#Principle Component Analysis\n",
    "def pca(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    #for reproducible result\n",
    "    np.random.seed(2)\n",
    "    \n",
    "    X_train, X_test = standard_scaler(X_train, X_test) #standardize data\n",
    "    \n",
    "    #rename columns after standardization\n",
    "    sensor_names = ['SensorMeasure{}'.format(i) for i in range(1,22)] \n",
    "    X_train = pd.DataFrame(X_train, columns = sensor_names).reset_index(drop = True)\n",
    "    X_test = pd.DataFrame(X_test, columns = sensor_names).reset_index(drop = True)\n",
    "\n",
    "    #-------------------------------Fitting Model----------------------------\n",
    "    # Make an instance of the Model\n",
    "    pca = PCA(0.95, random_state = 1) #95% of the variance (information) is retained\n",
    "\n",
    "    x1 = pca.fit_transform(X_train) #PCA based on train data\n",
    "    x2 = pca.transform(X_test) #transform test data\n",
    "    \n",
    "    #Graph to indicate information contains in each component\n",
    "    #fir = plt.figure(figsize=(8,5))\n",
    "    #sing_vals = np.arange(len(pca.components_)) + 1\n",
    "    #plt.plot(sing_vals, pca.explained_variance_ratio_, 'ro-', linewidth=2)\n",
    "    #plt.title('Scree Plot', fontsize = 20)\n",
    "    #plt.xlabel('Principal Component', fontsize = 20)\n",
    "    #plt.ylabel('Eigenvalue', fontsize = 20)\n",
    "    #plt.xticks(fontsize=10)\n",
    "    #plt.yticks(fontsize=10)\n",
    "    #------------------------------------------------------------------------\n",
    "    \n",
    "    #convert to data frame\n",
    "    X_train = pd.DataFrame(data = x1)\n",
    "    X_test = pd.DataFrame(data = x2)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0614a65",
   "metadata": {},
   "source": [
    "# Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f11bd59",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def polynomial_regression(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    #for reproducible result\n",
    "    np.random.seed(2)\n",
    "    \n",
    "    #------------------------------Train Model-------------------------------\n",
    "    degree=4 #degree of polynomial\n",
    "\n",
    "    polyreg_scaled=make_pipeline(PolynomialFeatures(degree),LinearRegression()) #pipeline to perform polynomial then linear regression\n",
    "    polyreg_scaled.fit(X_train,y_train.values.ravel()) #train model\n",
    "    #------------------------------------------------------------------------\n",
    "    \n",
    "    #------------------------------Predict X---------------------------------\n",
    "    y_pred_train = polyreg_scaled.predict(X_train) #predict on train data\n",
    "    y_pred_test = polyreg_scaled.predict(X_test) #predict on test data\n",
    "    #------------------------------------------------------------------------\n",
    "        \n",
    "    #---------------------------------Accuracy-------------------------------\n",
    "    # Use score method to get accuracy of model\n",
    "    accuracy_score = polyreg_scaled.score(X_test, y_test)\n",
    "    print('Accuracy of Polynomial Regression on test set: {:.2f}'.format(accuracy_score))\n",
    "    #------------------------------------------------------------------------\n",
    "    \n",
    "    #--------------------------------RMSE & R2-------------------------------\n",
    "    evaluate(y_train, y_pred_train, 'Train')\n",
    "    evaluate(y_test, y_pred_test, 'Test')\n",
    "    #------------------------------------------------------------------------\n",
    "    \n",
    "    filename = '../Dashboard UI/Dashboard UI/model/polynomial_model.sav'\n",
    "    pickle.dump(polyreg_scaled, open(filename, 'wb')) #save polynomial regression model\n",
    "    \n",
    "    #Colab use\n",
    "    #filename = 'polynomial_model.sav'\n",
    "    #pickle.dump(polyreg_scaled, open(filename, 'wb')) #save polynomial regression model\n",
    "    #files.download('polynomial_model.sav')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c4506f",
   "metadata": {},
   "source": [
    "# Working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "211b3197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Polynomial Regression on test set: 0.80\n",
      "Train set RMSE:18.057976066501144, R2:0.8122261550830668\n",
      "Test set RMSE:18.417279361800514, R2:0.8035774217748676\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = pca(train, test, train_y, test_y)\n",
    "\n",
    "polynomial_regression(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f98356",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
